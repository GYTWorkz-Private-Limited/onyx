# =============================================================================
# PULSE FILE-PARSER CONFIGURATION TEMPLATE
# =============================================================================
# Copy this file to .env and uncomment/modify settings as needed
# Default values are CPU-optimized for best performance on most systems

# LlamaParse Configuration (Optional - for cloud processing)
LLAMA_CLOUD_API_KEY=llx-joQGXHhCDkD1HDdlErk78VVSAsrVlXYrg80cVptLHfpbSDfF

# =============================================================================
# PERFORMANCE CONFIGURATION (CPU-Optimized Defaults - Revised)
# =============================================================================
# TESTING UPDATE: Initial settings (MAX_WORKERS=4, OCR_BATCH_SIZE=4) achieved only 0.4% improvement
# Revised settings below aim for 15-25% improvement through better parallelism
# Baseline: 587 seconds (21.8 sec/page) â†’ Realistic Target: 440-500 seconds (16-18 sec/page)

# GPU Acceleration (set to true if you have CUDA-compatible GPU)
ENABLE_GPU_ACCELERATION=false

# Worker Threads (CPU-optimized: balanced for 22-core system)
# Testing shows 4 workers may be too restrictive - try 6-8 for better parallelism
# For GPU systems: can increase to 8-12 workers
MAX_WORKERS=6

# OCR Batch Processing (CPU-optimized: balanced approach)
# Testing shows 4 may be too small - try 6-8 for better CPU utilization
# For GPU systems: can increase to 8-12 for better GPU utilization
OCR_BATCH_SIZE=6

# Image Processing Scale (preserved for quality)
# 0.8 = 80% resolution - optimal balance of speed vs accuracy
# Lower values (0.6-0.7) = faster but may reduce OCR accuracy
# Higher values (0.9-1.0) = better quality but slower processing
IMAGE_SCALE=0.8

# Memory Allocation (CPU-optimized: increased from 2048 to 4096)
# More memory reduces garbage collection overhead during processing
# Adjust based on available system RAM (recommended: 25-50% of total RAM)
MEMORY_LIMIT_MB=4096

# =============================================================================
# APPLICATION CONFIGURATION
# =============================================================================

# Server Settings
HOST=0.0.0.0
PORT=8000
DEBUG=false

# File Processing
OUTPUT_DIR=output
TEMP_DIR=temp
MAX_FILE_SIZE=50000000  # 50MB limit

# =============================================================================
# ADVANCED PERFORMANCE TUNING (Optional)
# =============================================================================

# CPU Threading Optimization (prevents oversubscription)
# Recommended values based on testing: 6 threads for balanced performance
# PYTORCH_NUM_THREADS=6
# OMP_NUM_THREADS=6
# MKL_NUM_THREADS=6

# Performance Monitoring (Optional)
# ENABLE_PERFORMANCE_MONITORING=true
# PERFORMANCE_TARGET_SECONDS_PER_PAGE=16.0  # Realistic target based on testing
# PERFORMANCE_WARNING_THRESHOLD_MINUTES=8

# Document Processing Options
# PDF_PROCESSING_MODE=fast
# LARGE_FILE_THRESHOLD_MB=10
# ENABLE_PARALLEL_PROCESSING=true

# =============================================================================
# EXTERNAL SERVICES (Optional)
# =============================================================================

# Redis Configuration (for caching)
# REDIS_URL=redis://localhost:6379

# Logging Configuration
# LOG_LEVEL=INFO
# LOG_FILE=logs/file_parser.log

# =============================================================================
# GPU ACCELERATION SETUP (Advanced Users)
# =============================================================================
# For 2-3 minute processing times (vs 4-6 minutes CPU-only):
# 1. Install CUDA PyTorch:
#    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
# 2. Set ENABLE_GPU_ACCELERATION=true
# 3. Optionally increase OCR_BATCH_SIZE=8 and MAX_WORKERS=6
# 4. Ensure NVIDIA drivers are installed and working
